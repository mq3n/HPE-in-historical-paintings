{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63a3d5c9",
   "metadata": {},
   "source": [
    "## Common functions\n",
    "The subroutines calculate the body proportion according to model, dataset and detected keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d48f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "POSE_COCO_BODY_PARTS = {\n",
    "    \"Nose\":0,\"Neck\":1,\"RShoulder\":2,\"RElbow\":3,\"RWrist\":4,\"LShoulder\":5,\"LElbow\":6,\"LWrist\":7,\n",
    "    \"RHip\":8,\"RKnee\":9,\"RAnkle\":10,\"LHip\":11,\"LKnee\":12,\"LAnkle\":13,\"REye\":14,\"LEye\":15,\"REar\":16,\"LEar\":17,\n",
    "    \"Background\":18\n",
    "}\n",
    "\n",
    "POSE_MPII_BODY_PARTS = {\n",
    "    \"Head\":0,\"Neck\":1,\"RShoulder\":2,\"RElbow\":3,\"RWrist\":4,\"LShoulder\":5,\"LElbow\":6,\"LWrist\":7,\n",
    "    \"RHip\":8,\"RKnee\":9,\"RAnkle\":10,\"LHip\":11,\"LKnee\":12,\"LAnkle\":13,\"Chest\":14,\"Background\":15\n",
    "}\n",
    "\n",
    "def all_presents(keypoints,model,*parts):\n",
    "    for part in parts:\n",
    "        if keypoints[model[part]][0] == 0 or keypoints[model[part]][0] == 0: return False\n",
    "    return True\n",
    "\n",
    "def body_part_length(keypoints,model,part1,part2):\n",
    "    return math.sqrt(\n",
    "        (keypoints[model[part1]][0]-keypoints[model[part2]][0])**2 + \n",
    "        (keypoints[model[part1]][1]-keypoints[model[part2]][1])**2 + \n",
    "        (keypoints[model[part1]][2]-keypoints[model[part2]][2])**2 ) \\\n",
    "            if all_presents(keypoints,model,part1,part2) else 0\n",
    "\n",
    "## Coco dataset\n",
    "def coco_head(keypoints):\n",
    "    return body_part_length(keypoints,POSE_COCO_BODY_PARTS,'Nose','Neck')\n",
    "\n",
    "def coco_rshoulder(keypoints):\n",
    "    return body_part_length(keypoints,POSE_COCO_BODY_PARTS,'RShoulder','Neck')\n",
    "\n",
    "def coco_lshoulder(keypoints):\n",
    "    return body_part_length(keypoints,POSE_COCO_BODY_PARTS,'LShoulder','Neck')\n",
    "\n",
    "def coco_avg_shoulder(keypoints):\n",
    "    rs = coco_rshoulder(keypoints)\n",
    "    ls = coco_lshoulder(keypoints)\n",
    "    if rs > 0 and ls > 0:\n",
    "        return (rs+ls)/2\n",
    "    elif rs > 0 and ls <= 0:\n",
    "        return rs\n",
    "    else:\n",
    "        return ls\n",
    "    \n",
    "def coco_body(keypoints):\n",
    "    leg = max( \n",
    "        body_part_length(keypoints,POSE_COCO_BODY_PARTS,'LHip','LKnee')+\n",
    "        body_part_length(keypoints,POSE_COCO_BODY_PARTS,'LKnee','LAnkle') \\\n",
    "        if all_presents(keypoints,POSE_COCO_BODY_PARTS,'LHip','LKnee','LAnkle') else 0,\n",
    "        body_part_length(keypoints,POSE_COCO_BODY_PARTS,'RHip','RKnee')+\n",
    "        body_part_length(keypoints,POSE_COCO_BODY_PARTS,'RKnee','RAnkle') \\\n",
    "        if all_presents(keypoints,POSE_COCO_BODY_PARTS,'RHip','RKnee','RAnkle') else 0)\n",
    "    body = body_part_length(keypoints,POSE_COCO_BODY_PARTS,'Nose','Neck') + \\\n",
    "        max(body_part_length(keypoints,POSE_COCO_BODY_PARTS,'LHip','Neck'),body_part_length(keypoints,POSE_COCO_BODY_PARTS,'RHip','Neck')) + \\\n",
    "        leg \n",
    "    return (body if leg > 0 else 0)\n",
    "\n",
    "def coco_corpus(keypoints):\n",
    "    return max(body_part_length(keypoints,POSE_COCO_BODY_PARTS,'LHip','Neck'),\n",
    "               body_part_length(keypoints,POSE_COCO_BODY_PARTS,'RHip','Neck'))\n",
    "\n",
    "## MPII dataset\n",
    "def mpi_head(keypoints):\n",
    "    return body_part_length(keypoints,POSE_MPII_BODY_PARTS,'Head','Neck')\n",
    "\n",
    "def mpi_rshoulder(keypoints):\n",
    "    return body_part_length(keypoints,POSE_MPII_BODY_PARTS,'RShoulder','Neck')\n",
    "\n",
    "def mpi_lshoulder(keypoints):\n",
    "    return body_part_length(keypoints,POSE_MPII_BODY_PARTS,'LShoulder','Neck')\n",
    "\n",
    "def mpi_avg_shoulder(keypoints):\n",
    "    rs = mpi_rshoulder(keypoints)\n",
    "    ls = mpi_lshoulder(keypoints)\n",
    "    if rs > 0 and ls > 0:\n",
    "        return (rs+ls)/2\n",
    "    elif rs > 0 and ls <= 0:\n",
    "        return rs\n",
    "    else:\n",
    "        return ls\n",
    "    \n",
    "def mpi_body(keypoints):\n",
    "    leg = max( \n",
    "        body_part_length(keypoints,POSE_MPII_BODY_PARTS,'LHip','LKnee')+\n",
    "        body_part_length(keypoints,POSE_MPII_BODY_PARTS,'LKnee','LAnkle') \\\n",
    "        if all_presents(keypoints,POSE_MPII_BODY_PARTS,'LHip','LKnee','LAnkle') else 0,\n",
    "        body_part_length(keypoints,POSE_MPII_BODY_PARTS,'RHip','RKnee')+\n",
    "        body_part_length(keypoints,POSE_MPII_BODY_PARTS,'RKnee','RAnkle') \\\n",
    "        if all_presents(keypoints,POSE_MPII_BODY_PARTS,'RHip','RKnee','RAnkle') else 0)\n",
    "    body = body_part_length(keypoints,POSE_MPII_BODY_PARTS,'Head','Neck') + \\\n",
    "        max(body_part_length(keypoints,POSE_MPII_BODY_PARTS,'LHip','Neck'),body_part_length(keypoints,POSE_MPII_BODY_PARTS,'RHip','Neck')) + \\\n",
    "        leg \n",
    "    return (body if leg > 0 else 0)\n",
    "\n",
    "def mpi_corpus(keypoints):\n",
    "    return max(body_part_length(keypoints,POSE_COCO_BODY_PARTS,'LHip','Neck'),\n",
    "               body_part_length(keypoints,POSE_COCO_BODY_PARTS,'RHip','Neck'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c955b567",
   "metadata": {},
   "source": [
    "## Building a proportion database by analyzing historical paintings with selected HPE architectures\n",
    "The cell below processes the collection of historical painting by architecture built of the detector and algorithm. The result keypoints are associated to body parts and then basic proportions are calculated. Finally the result is saved to json file for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404454b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.stats import shapiro, levene, bartlett, friedmanchisquare, kruskal\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from mmpose.apis import (inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result, process_mmdet_results)\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "local_runtime = False\n",
    "\n",
    "try:\n",
    "  from google.colab.patches import cv2_imshow  # for image visualization in colab\n",
    "except:\n",
    "  local_runtime = True\n",
    "\n",
    "\n",
    "algoritms = {\n",
    "    'Deeppose + Resnet on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/deeppose/mpii/res101_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/deeppose/deeppose_res101_mpii_256x256-87516a90_20210205.pth'\n",
    "        },\n",
    "    'Topdown Heatmap + Resnet on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/res101_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/resnet/res101_mpii_256x256-416f5d71_20200812.pth'\n",
    "        },\n",
    "    'Topdown Heatmap + Scnet on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/scnet101_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/scnet/scnet101_mpii_256x256-b4c2d184_20200812.pth'\n",
    "        },\n",
    "    'Topdown Heatmap + Resnetv1d on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/resnetv1d152_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/resnetv1d/resnetv1d152_mpii_256x256-8b10a87c_20200812.pth'\n",
    "        },\n",
    "    'Topdown Heatmap + Seresnet on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/seresnet101_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/seresnet/seresnet101_mpii_256x256-0ba14ff5_20200927.pth'\n",
    "        },\n",
    "    'Topdown Heatmap + Shufflenetv1 on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/shufflenetv1_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/shufflenetv1/shufflenetv1_mpii_256x256-dcc1c896_20200925.pth'\n",
    "        },\n",
    "    'Topdown Heatmap + Hrnet + Dark on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/hrnet_w48_mpii_256x256_dark.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_mpii_256x256_dark-0decd39f_20200927.pth'\n",
    "        }, \n",
    "    'Topdown Heatmap + Resnext on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/resnext152_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/resnext/resnext152_mpii_256x256-df302719_20200927.pth'\n",
    "        }, \n",
    "    'Topdown Heatmap + Litehrnet on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/litehrnet_30_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/litehrnet/litehrnet30_mpii_256x256-faae8bd8_20210622.pth'\n",
    "        }, \n",
    "    'Topdown Heatmap + Shufflenetv2 on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/shufflenetv2_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/shufflenetv2/shufflenetv2_mpii_256x256-4fb9df2d_20200925.pth'\n",
    "        },  \n",
    "    'Topdown Heatmap + Hrnet on Mpii':\n",
    "        {'pose_config':'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/hrnet_w48_mpii_256x256.py',\n",
    "         'pose_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_mpii_256x256-92cab7bd_20200812.pth'\n",
    "        },       \n",
    "    }\n",
    "\n",
    "detectors = {\n",
    "    'Faster-RCNN':\n",
    "        {'det_config':'demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py',\n",
    "         'det_checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "        },\n",
    "    'Retina':\n",
    "        {'det_config':'../mmdetection/configs/retinanet/retinanet_r50_fpn_mstrain_640-800_3x_coco.py',\n",
    "         'det_checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/retinanet/retinanet_r50_fpn_mstrain_3x_coco/retinanet_r50_fpn_mstrain_3x_coco_20210718_220633-88476508.pth'\n",
    "        },\n",
    "    'Yolo':\n",
    "        {'det_config':'../mmdetection/configs/yolo/yolov3_d53_mstrain-416_273e_coco.py',\n",
    "         'det_checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/yolo/yolov3_d53_mstrain-416_273e_coco/yolov3_d53_mstrain-416_273e_coco-2b60fcd9.pth'\n",
    "        },      \n",
    "}\n",
    "\n",
    "for det in detectors:\n",
    "    for algo in algoritms:\n",
    "        for threshold in [0.3,0.5,0.7]:\n",
    "            print(\"%s %s %s\" % (det,algo,threshold))\n",
    "            # initialize pose model\n",
    "            pose_model = init_pose_model(algoritms[algo]['pose_config'], algoritms[algo]['pose_checkpoint'])\n",
    "            # initialize detector\n",
    "            det_model = init_detector(detectors[det]['det_config'], detectors[det]['det_checkpoint'])\n",
    "\n",
    "            path_to_process = ['gothic','renaissance','baroque','rococo','classicism','romantic']\n",
    "\n",
    "            result = {}\n",
    "            test_data = {}\n",
    "            for path in path_to_process:\n",
    "                fullpath = img = '../data/paintings/' + path\n",
    "                imgfiles = [f for f in listdir(fullpath) if isfile(join(fullpath, f))]\n",
    "\n",
    "                agw=[]\n",
    "                agr=[]\n",
    "                agb=[]\n",
    "\n",
    "                for img in imgfiles:\n",
    "                    mmdet_results = inference_detector(det_model, fullpath + \"/\" + img)\n",
    "                    person_results = process_mmdet_results(mmdet_results, cat_id=1)\n",
    "                    pose_results, returned_outputs = inference_top_down_pose_model(pose_model,\n",
    "                       fullpath + \"/\" + img,\n",
    "                       person_results,\n",
    "                       bbox_thr=threshold,\n",
    "                       format='xyxy',\n",
    "                       dataset=pose_model.cfg.data.test.type) \n",
    "                    # calculate each person in picture\n",
    "                    for pose in pose_results:\n",
    "                        head = mpi_head(pose['keypoints'])\n",
    "                        shoulder = mpi_avg_shoulder(pose['keypoints'])\n",
    "                        body = mpi_body(pose['keypoints'])\n",
    "                        corpus = mpi_corpus(pose['keypoints'])\n",
    "                        gw = 0\n",
    "                        gr = 0\n",
    "                        gb = 0\n",
    "                        if shoulder>0 and head>0:\n",
    "                            gr = head/shoulder\n",
    "                            agr.append(gr)\n",
    "                        if body>0 and head>0: \n",
    "                            gw = head/body\n",
    "                            agw.append(gw)\n",
    "                        if corpus>0 and head>0:  \n",
    "                            gb = head/corpus\n",
    "                            agb.append(gb)\n",
    "\n",
    "                test_data[path]={}\n",
    "                test_data[path]['gr']=agr\n",
    "                test_data[path]['gw']=agw\n",
    "                test_data[path]['gb']=agb\n",
    "\n",
    "            with open('json/'+det+'_'+algo+'_'+str(threshold)+'.json', 'w') as outfile:\n",
    "                json.dump(test_data, outfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fdd22b4",
   "metadata": {},
   "source": [
    "## Calculation of statistics for models\n",
    "The cells below uses json files to calculate proper statistical significance tests.\n",
    "\n",
    "### Kruskal–Wallis and Shapiro-Wilk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225603e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.stats import shapiro, levene, bartlett, friedmanchisquare, kruskal\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "jpath = '../data/json/'\n",
    "\n",
    "files = [f for f in listdir(jpath) if isfile(join(jpath, f))]\n",
    "\n",
    "for f in files:\n",
    "    styles = ['gothic','renaissance','baroque','rococo','classicism','romantic']\n",
    "\n",
    "    data = json.load(open(join(jpath, f)))\n",
    "\n",
    "    akruskal = {}\n",
    "    for d in ['gb','gw','gr']:\n",
    "        stat, p = kruskal(data['gothic'][d],data['renaissance'][d],data['baroque'][d],\n",
    "            data['rococo'][d],data['classicism'][d],data['romantic'][d])\n",
    "        if p > 0.05:\n",
    "            akruskal[d] = '-'\n",
    "            #print('populations are similar')\n",
    "        else:\n",
    "            #print('populations are different')\n",
    "            akruskal[d] = '+'\n",
    "        \n",
    "    \n",
    "    for style in styles:\n",
    "        ashapiro = {}\n",
    "        ile = {}\n",
    "        for d in ['gb','gw','gr']:\n",
    "            stat, p0 = shapiro(data[style][d])\n",
    "            ile[d] = len(data[style][d])\n",
    "            if p0 > 0.05:\n",
    "                ashapiro[d] = '+'\n",
    "                #print('probably Gaussian')\n",
    "            else:\n",
    "                #print('probably not Gaussian')\n",
    "                ashapiro[d] = '-'\n",
    "            \n",
    "            \n",
    "        print(\"%s;%s;%s;%s;%s;%s;%s;%s;%s;%s;%s;%s\" % (f,style,d,ile['gb'],ile['gw'],ile['gr'],ashapiro['gb'],ashapiro['gw'],ashapiro['gr'],akruskal['gb'],akruskal['gw'],akruskal['gr']) )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b695bb0",
   "metadata": {},
   "source": [
    "### Standard deviation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.stats import shapiro, levene, bartlett, friedmanchisquare, kruskal\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "jpath = '../data/json/'\n",
    "\n",
    "files = [f for f in listdir(jpath) if isfile(join(jpath, f))]\n",
    "\n",
    "for f in files:\n",
    "    styles = ['gothic','renaissance','baroque','rococo','classicism','romantic']\n",
    "\n",
    "    data = json.load(open(join(jpath, f)))\n",
    "\n",
    "    line = ''\n",
    "    for style in styles:\n",
    "        for d in ['gb','gw','gr']:\n",
    "            line += ';' + str(np.std(data[style][d]))\n",
    "            \n",
    "    print(\"%s;%s\" % (f,line ))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f84fcbb7",
   "metadata": {},
   "source": [
    "### Median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.stats import shapiro, levene, bartlett, friedmanchisquare, kruskal\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "jpath = '../data/json/'\n",
    "\n",
    "files = [f for f in listdir(jpath) if isfile(join(jpath, f))]\n",
    "\n",
    "for f in files:\n",
    "    #print(f)\n",
    "    styles = ['gothic','renaissance','baroque','rococo','classicism','romantic']\n",
    "\n",
    "    data = json.load(open(join(jpath, f)))\n",
    "\n",
    "    line = ''\n",
    "    for style in styles:\n",
    "        for d in ['gb','gw','gr']:\n",
    "            line += ';' + str(np.median(data[style][d]))\n",
    "            \n",
    "    print(\"%s;%s\" % (f,line ))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3e2361d",
   "metadata": {},
   "source": [
    "### posthoc Nemanyi Test for Faster-RCNN_Topdown Heatmap + Scnet on Mpii_0.3.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e300aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.stats import shapiro, levene, bartlett, friedmanchisquare, kruskal\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scikit_posthocs import posthoc_nemenyi_friedman, posthoc_nemenyi, posthoc_ttest, posthoc_dunn\n",
    "from scipy.stats import shapiro, levene, bartlett, friedmanchisquare, kruskal, f_oneway, wilcoxon, mannwhitneyu\n",
    "\n",
    "jfile = '../data/json/Faster-RCNN_Topdown Heatmap + Scnet on Mpii_0.3.json'\n",
    "data = json.load(open(jfile))\n",
    "styles = ['gothic','renaissance','baroque','rococo','classicism','romantic']\n",
    "for style1 in styles:\n",
    "    for style2 in styles:\n",
    "        for d in ['gb','gw','gr']:\n",
    "            print(d)\n",
    "            x = [\n",
    "                 data[style1][d],\n",
    "                 data[style2][d]\n",
    "                ]\n",
    "            result =  sp.posthoc_nemenyi(x)\n",
    "            print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openmmlab]",
   "language": "python",
   "name": "conda-env-openmmlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
